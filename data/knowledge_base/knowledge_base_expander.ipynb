{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "import io\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_API_KEY = getpass(\"Enter your Hugging Face API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "client = InferenceClient(\n",
    "    model=MODEL,\n",
    "    token=HUGGINGFACE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a food science expert specializing in culinary chemistry and taste perception. You will enhance a taste profile database by adding preparation method variations for ingredients.\n",
    "\n",
    "CONTEXT: \n",
    "- Each ingredient has 5 taste dimensions: salty, umami, sweet, sour, bitter (scored 0-1)\n",
    "- Preparation methods chemically transform ingredients, altering their taste profiles\n",
    "- Common transformations include: fermentation, pickling, roasting, caramelization, curing, smoking, drying, blanching, grilling\n",
    "\n",
    "RULES:\n",
    "1.  **Analyze the Base Ingredient:** Understand what it is (e.g., a vegetable, a dairy product, a meat).\n",
    "2.  **Generate Variations:** Brainstorm common cooking methods, processing techniques, or specific types related to the ingredient. The new name should be \"Processed Ingredient\" (e.g., \"Fermented Cabbage\", \"Smoked Salmon\", \"Blue Cheese\"). Include both traditional and modern preparation techniques.\n",
    "3.  **Estimate Taste Profile:** For each new variation, create a new 5-point taste profile (salty, umami, sweet, sour, bitter) with scores from 0.0 to 1.0. The scores MUST logically reflect the change caused by the process. Consider how these methods chemically transform the taste compounds. For example, fermenting increases sourness, curing increases saltiness, and roasting can increase sweetness and bitterness (caramelization).\n",
    "4.  **Format Output Correctly:** The output MUST be only the new CSV lines. Do not include headers, explanations, or the original line. \n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Only generate preparations that actually exist in culinary practice\n",
    "- Score adjustments should reflect real chemical changes, not assumptions\n",
    "- For ingredients rarely processed (e.g., salt), return only the original\n",
    "- Include a note explaining the dominant chemical/taste change\n",
    "\n",
    "**OUTPUT FORMAT** STRICTLY ONLY RETURN A LIST OF NEW CSV LINES with the following columns:\n",
    "entity_name,entity_type,salty,umami,sweet,sour,bitter,notes\n",
    "\n",
    "EXAMPLES:\n",
    "Input: cabbage,ingredient,0.0,0.2,0.3,0.1,0.4,\"Category: Vegetable\"\n",
    "Output:\n",
    "cabbage_fermented,ingredient_processed,0.2,0.6,0.1,0.8,0.3,\"Lactic acid fermentation creates glutamates (umami) and acids (sour)\"\n",
    "cabbage_pickled,ingredient_processed,0.4,0.1,0.2,0.9,0.2,\"Vinegar pickling adds acetic acid (sour) and salt\"'\n",
    "cabbage_roasted,ingredient_processed,0.1,0.4,0.5,0.0,0.5,\"Maillard reaction creates savory-sweet compounds\"'\n",
    "cabbage_blanched,ingredient_processed,0.0,0.1,0.2,0.0,0.2,\"Blanching reduces bitter glucosinolates\"\n",
    "\n",
    "Input: pork,ingredient,0.1,0.7,0.2,0.0,0.1,\"Category: Meat\"\n",
    "Output:\n",
    "pork_cured,ingredient_processed,0.9,0.8,0.1,0.0,0.2,\"Salt curing and nitrites enhance umami\"\n",
    "pork_smoked,ingredient_processed,0.5,0.9,0.3,0.0,0.4,\"Smoke compounds add umami and slight bitterness\"\n",
    "pork_caramelized,ingredient_processed,0.2,0.8,0.6,0.0,0.3,\"Surface caramelization creates sweet-savory crust\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Generate the processed variations for this ingredient:\n",
    "{ingredient_row}\n",
    "\n",
    "**IMPORTANT**: Your response must contain ONLY the raw CSV lines and nothing else. Do not include any analysis, explanations, or introductory text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_ingredient(row, client):\n",
    "    row_str = f\"{row['entity_name']},{row['entity_type']},{row['salty']},\"\n",
    "    row_str += f\"{row['umami']},{row['sweet']},{row['sour']},{row['bitter']},\\\"{row['notes']}\\\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(ingredient_row=row_str)}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat_completion(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=2048,\n",
    "        temperature=0.0,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "    clean_output = output.strip().strip(\"[]'\\\" \")\n",
    "    \n",
    "    string_io = io.StringIO(clean_output)\n",
    "    reader = csv.reader(string_io, skipinitialspace=True)\n",
    "    \n",
    "    new_rows_as_dicts = []\n",
    "    headers = ['entity_name', 'entity_type', 'salty', 'umami', 'sweet', 'sour', 'bitter', 'notes']\n",
    "    \n",
    "    for row_values in reader:\n",
    "        # 3. Ensure the row has the correct number of columns\n",
    "        if len(row_values) == len(headers):\n",
    "            # 4. Create a dictionary and append it\n",
    "            new_rows_as_dicts.append(dict(zip(headers, row_values)))\n",
    "    \n",
    "    return new_rows_as_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting knowledge base expansion...\n",
      "[1/935] Expanding 'bakery products'...\n",
      "  -> Generated 3 new variations.\n",
      "[2/935] Expanding 'bread'...\n",
      "  -> Generated 4 new variations.\n",
      "[3/935] Expanding 'rye bread'...\n",
      "  -> Generated 4 new variations.\n",
      "[4/935] Expanding 'wheaten bread'...\n",
      "  -> Generated 3 new variations.\n",
      "[5/935] Expanding 'white bread'...\n",
      "  -> Generated 3 new variations.\n",
      "[6/935] Expanding 'wholewheat bread'...\n",
      "  -> Generated 3 new variations.\n",
      "[7/935] Expanding 'wort'...\n",
      "  -> Generated 3 new variations.\n",
      "[8/935] Expanding 'arrack'...\n",
      "  -> Generated 3 new variations.\n",
      "[9/935] Expanding 'beer'...\n",
      "  -> Generated 3 new variations.\n",
      "[10/935] Expanding 'bantu beer'...\n",
      "  -> Generated 3 new variations.\n",
      "[11/935] Expanding 'brandy'...\n",
      "  -> Generated 3 new variations.\n",
      "[12/935] Expanding 'anise brandy'...\n",
      "  -> Generated 2 new variations.\n",
      "[13/935] Expanding 'apple brandy'...\n",
      "  -> Generated 2 new variations.\n",
      "[14/935] Expanding 'armagnac brandy'...\n",
      "  -> Generated 4 new variations.\n",
      "[15/935] Expanding 'blackberry brandy'...\n",
      "  -> Generated 3 new variations.\n",
      "[16/935] Expanding 'cherry brandy'...\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68b8e0f7-4256b6af6aca660e6cf2dea4;b9a2d966-41f3-4d85-b9f6-aee3c4385f78)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/cmo_edge/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cmo_edge/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m all_rows\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 2. Get the new, expanded rows\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m new_rows \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_ingredient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_rows:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  -> Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_rows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new variations.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m, in \u001b[0;36mexpand_ingredient\u001b[0;34m(row, client)\u001b[0m\n\u001b[1;32m      3\u001b[0m row_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumami\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msour\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbitter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: SYSTEM_PROMPT},\n\u001b[1;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(ingredient_row\u001b[38;5;241m=\u001b[39mrow_str)}\n\u001b[1;32m      8\u001b[0m ]\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     18\u001b[0m clean_output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cmo_edge/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:923\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    895\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload_model,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    915\u001b[0m }\n\u001b[1;32m    916\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m    917\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    918\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    922\u001b[0m )\n\u001b[0;32m--> 923\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cmo_edge/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:279\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cmo_edge/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/together/v1/chat/completions (Request ID: Root=1-68b8e0f7-4256b6af6aca660e6cf2dea4;b9a2d966-41f3-4d85-b9f6-aee3c4385f78)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('knowledge_base_average.csv')\n",
    "\n",
    "\n",
    "all_rows = []\n",
    "    \n",
    "print(\"Starting knowledge base expansion...\")\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"[{index + 1}/{len(df)}] Expanding '{row['entity_name']}'...\")\n",
    "    \n",
    "    # 1. Add the original row to our new list\n",
    "    all_rows.append(row.to_dict())\n",
    "    \n",
    "    # 2. Get the new, expanded rows\n",
    "    new_rows = expand_ingredient(row, client)\n",
    "    \n",
    "    if new_rows:\n",
    "        print(f\"  -> Generated {len(new_rows)} new variations.\")\n",
    "        all_rows.extend(new_rows)\n",
    "    else:\n",
    "        print(\"  -> No new variations generated or an error occurred.\")\n",
    "    \n",
    "    # 3. Be polite to the API to avoid rate limits\n",
    "    time.sleep(1) \n",
    "\n",
    "print(\"\\nExpansion complete.\")\n",
    "\n",
    "# Create the final augmented DataFrame\n",
    "augmented_df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Save to the new CSV file\n",
    "augmented_df.to_csv(\"knowledge_base_average_processed.csv\", index=False)\n",
    "print(f\"Augmented knowledge base saved to 'temp_new'.\")\n",
    "print(f\"Original size: {len(df)} rows. New size: {len(augmented_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmo_edge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
